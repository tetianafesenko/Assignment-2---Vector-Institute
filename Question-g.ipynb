{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) With the help of ChatGPT, replace the decision tree classifier with Random forest or XGBoost. XGBoost is currently the state of the art for heterogeneous tabular data and builds decision trees sequentially such that each subsequent tree corrects earlier mistakes. XGBoost can reveal important features in the decision process. Identify the most important features for your classification task. [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "petal length (cm): 0.43999397414456937\n",
      "petal width (cm): 0.4215215887397244\n",
      "sepal length (cm): 0.10809762464246378\n",
      "sepal width (cm): 0.030386812473242528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Train a Random Forest model with 100 trees\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the feature importances for the Random Forest model\n",
    "importances = rf_clf.feature_importances_\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "print(\"Feature importances:\")\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{iris.feature_names[idx]}: {importances[idx]}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "petal length (cm): 0.7524506449699402\n",
      "petal width (cm): 0.2074233740568161\n",
      "sepal width (cm): 0.02904883772134781\n",
      "sepal length (cm): 0.011077101342380047\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost model with 100 trees\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the feature importances for the XGBoost model\n",
    "importances = xgb_clf.feature_importances_\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "print(\"Feature importances:\")\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{iris.feature_names[idx]}: {importances[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a62fd136276fed91f6bd43fed7357d0a16a5b27a1b0724ce6c7fbeb3eb3270d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
